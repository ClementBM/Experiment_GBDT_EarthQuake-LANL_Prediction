{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LANL Earthquake Prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClementBM/Experiment_GBDT_EarthQuake-LANL_Prediction/blob/master/LANL_Earthquake_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FQWVVuVZed68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import some packages\n",
        "Common packages and CatBoostRegressor"
      ]
    },
    {
      "metadata": {
        "id": "xexSg55sUsKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# math operations\n",
        "import numpy as np\n",
        "import math\n",
        "# data preprocessing\n",
        "import pandas as pd\n",
        "# signal filtering\n",
        "from scipy import signal as sg\n",
        "import scipy\n",
        "from scipy.signal import hilbert, chirp\n",
        "from scipy.signal import find_peaks\n",
        "from scipy import interpolate\n",
        "from scipy import fftpack\n",
        "# machine learning\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "# serialization\n",
        "import pickle\n",
        "# io\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "# parallel loop\n",
        "from joblib import Parallel, delayed\n",
        "import time\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N6QET58hs2V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Functions for serialize and deserialize data"
      ]
    },
    {
      "metadata": {
        "id": "HGjt7QoWexs_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deserialize(filename):\n",
        "    f = open(filename, \"rb\")\n",
        "    d = pickle.load(f)\n",
        "    f.close()\n",
        "    return d\n",
        "\n",
        "def serialize(obj,filename):\n",
        "    f = open(filename, \"wb\")\n",
        "    d = pickle.dump(obj,f)\n",
        "    f.close()\n",
        "    return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9w-qEeM4mhCJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Look at the data"
      ]
    },
    {
      "metadata": {
        "id": "Piv4Pu7Qe1Gk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data file path\n",
        "trainPath = \"train.csv\"\n",
        "testPath = \"testdata\"\n",
        "\n",
        "# Get a sample of training data\n",
        "trainSet = pd.read_csv(trainPath, nrows=2400000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
        "\n",
        "# Plot based on both features\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "plt.title(\"Acoustic data and time to failure: 1% sampled data\")\n",
        "plt.plot(train['acoustic_data'], color='r')\n",
        "ax1.set_ylabel('acoustic data', color='r')\n",
        "plt.legend(['acoustic data'], loc=(0.01, 0.95))\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(train['time_to_failure'], color='b')\n",
        "ax2.set_ylabel('time to failure', color='b')\n",
        "plt.legend(['time to failure'], loc=(0.01, 0.9))\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "slcEzMbqmnz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Features Engineering with FFT and statistic metrics"
      ]
    },
    {
      "metadata": {
        "id": "rYyKdB20es8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def GenFeatures(X):\n",
        "    strain = []\n",
        "    strain.append(X.mean())\n",
        "    strain.append(X.kurtosis())\n",
        "    strain.append(X.skew())\n",
        "    strain.append(np.quantile(X,0.05))\n",
        "    strain.append(np.quantile(X,0.95))\n",
        "    strain.append(np.abs(X).mean())\n",
        "    return strain\n",
        "\n",
        "def GenFeaturesFromFft(X):\n",
        "    strain = []\n",
        "    strain.append(X.min()) \n",
        "    strain.append(X.kurtosis())\n",
        "    strain.append(X.skew())\n",
        "    strain.append(np.quantile(X,0.05))\n",
        "    return strain\n",
        "\n",
        "def CalculateFeatures(acousticData, timeToFailure):\n",
        "    x = GenerateFeatures(acousticData)\n",
        "    y = timeToFailure.values[-1]\n",
        "    return x, y\n",
        "\n",
        "def FourierTransform(x):\n",
        "    fft = scipy.fftpack.fft(x)\n",
        "    psd = np.abs(fft)\n",
        "    fftfreq = scipy.fftpack.fftfreq(len(psd), 1.0/4_000_000)\n",
        "    i = fftfreq > 0\n",
        "    result = psd[i]\n",
        "    return result\n",
        "\n",
        "def GenerateFeatures(acousticData):    \n",
        "    xDetrend = sg.detrend(acousticData)\n",
        "    fft = FourierTransform(xDetrend)\n",
        "    \n",
        "    x2 = GenFeaturesFromFft(pd.Series(fft))\n",
        "    x = np.concatenate((x1, x2), axis=0)\n",
        "    \n",
        "    xSerie = pd.Series(x)\n",
        "    return xSerie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zc2gyGi2m5ot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Calculate features"
      ]
    },
    {
      "metadata": {
        "id": "DwMWklTtmy3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "number_lines = sum(1 for line in open(trainPath))\n",
        "print(number_lines)\n",
        "\n",
        "train = pd.read_csv(\n",
        "    trainPath,\n",
        "    iterator=True,\n",
        "    chunksize=150_000,\n",
        "    dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
        "\n",
        "xy = Parallel(n_jobs=-1)(delayed(CalculateFeatures)(df['acoustic_data'], df['time_to_failure']) for df in train)\n",
        "\n",
        "x1, y1= zip(*xy)\n",
        "\n",
        "X_train = pd.DataFrame()\n",
        "y_train = pd.Series()\n",
        "\n",
        "for i in range(len(x1)):\n",
        "    X_train = X_train.append(x1[i], ignore_index=True)\n",
        "    y_train = y_train.append(pd.Series(y1[i]))\n",
        "\n",
        "print(X_train)\n",
        "print(y_train)\n",
        "\n",
        "serialize(X_train, \"x_train-bak.bin\")\n",
        "serialize(y_train, \"y_train-bak.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TV75-dA1nAZi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build model and train on data"
      ]
    },
    {
      "metadata": {
        "id": "wfqDynUVe5Oo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_pool = Pool(X_train, y_train)\n",
        "model = CatBoostRegressor(iterations=10000, loss_function='MAE', boosting_type='Ordered')\n",
        "model.fit(X_train, y_train, silent=True)\n",
        "\n",
        "serialize(model, \"model-bak.bin\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v0VorYbunITr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "metadata": {
        "id": "7Awh-x-jnKFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model.best_score_)\n",
        "print(model.feature_importances_)\n",
        "print(model.tree_count_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XrfJ0O33nSTb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict on testset"
      ]
    },
    {
      "metadata": {
        "id": "F_nJOaS9e-sE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataFiles = [f for f in listdir(testPath) if isfile(join(testPath, f))]\n",
        "\n",
        "################################################\n",
        "def Predict(testPath, dataFile):\n",
        "    x = pd.read_csv(os.path.join(testPath, dataFile))\n",
        "    xFeature = GenerateFeatures(x['acoustic_data'])\n",
        "    prediction = model.predict(xFeature.to_frame().transpose())\n",
        "    cell = []\n",
        "    cell.append(dataFile.replace(\".csv\",\"\"))\n",
        "    cell.append(prediction[0])\n",
        "    return cell\n",
        "\n",
        "predictionsP = Parallel(n_jobs=-1)(delayed(Predict)(testPath, dataFile) for dataFile in dataFiles)\n",
        "\n",
        "predictions = pd.DataFrame(columns=['seg_id', 'time_to_failure'])\n",
        "\n",
        "for i in range(len(predictionsP)):\n",
        "    predictions.loc[i] = predictionsP[i]\n",
        "################################################\n",
        "\n",
        "print(predictions)\n",
        "predictions.to_csv(\"predictions-bak.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}